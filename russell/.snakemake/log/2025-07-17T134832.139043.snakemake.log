Assuming unrestricted shared filesystem usage.
None
host: CARLOSs-MacBook-Pro.local
Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 4
Rules claiming more threads will be scaled down.
Job stats:
job             count
------------  -------
all                 1
python_write        1
shell_write         1
total               3

Select jobs to execute...
Execute 2 jobs...
[Thu Jul 17 13:48:32 2025]
localrule shell_write:
    output: s2_shell.txt
    jobid: 1
    reason: Missing output files: s2_shell.txt
    resources: tmpdir=/var/folders/q3/5zmml3z16g93bd3gdlq6bftm0000gp/T
[Thu Jul 17 13:48:32 2025]
localrule python_write:
    output: s2_python.txt
    jobid: 2
    reason: Missing output files: s2_python.txt; Code has changed since last execution
    resources: tmpdir=/var/folders/q3/5zmml3z16g93bd3gdlq6bftm0000gp/T
[Thu Jul 17 13:48:32 2025]
Finished jobid: 1 (Rule: shell_write)
1 of 3 steps (33%) done
Traceback (most recent call last):

  File "/Users/russell/.local/share/mamba/envs/snakemake_env/lib/python3.11/site-packages/snakemake/executors/local.py", line 232, in spawn_job
    subprocess.check_call(cmd, shell=True)

  File "/Users/russell/.local/share/mamba/envs/snakemake_env/lib/python3.11/subprocess.py", line 413, in check_call
    raise CalledProcessError(retcode, cmd)

subprocess.CalledProcessError: Command 'cd /Users/russell/Code/snakehive/russell && /Users/russell/.local/share/mamba/envs/snakemake_env/bin/python3.11 -m snakemake --snakefile '/Users/russell/Code/snakehive/russell/step_2' --target-jobs 'python_write:' --allowed-rules python_write --cores 4 --attempt 1 --force-use-threads  --force --target-files-omit-workdir-adjustment --max-inventory-time 0 --nocolor --notemp --no-hooks --nolock --ignore-incomplete --rerun-triggers software-env params code input mtime --conda-frontend 'conda' --shared-fs-usage input-output persistence sources storage-local-copies source-cache software-deployment --wrapper-prefix 'https://github.com/snakemake/snakemake-wrappers/raw/' --latency-wait 5 --scheduler 'ilp' --local-storage-prefix base64//LnNuYWtlbWFrZS9zdG9yYWdl --scheduler-solver-path '/Users/russell/.local/share/mamba/envs/snakemake_env/bin' --default-resources base64//dG1wZGlyPXN5c3RlbV90bXBkaXI= --quiet progress rules host --mode 'subprocess' --local-groupid 'local'' returned non-zero exit status 1.


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File "/Users/russell/.local/share/mamba/envs/snakemake_env/lib/python3.11/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/Users/russell/.local/share/mamba/envs/snakemake_env/lib/python3.11/site-packages/snakemake/executors/local.py", line 247, in cached_or_run
    run_func(*args)

  File "/Users/russell/.local/share/mamba/envs/snakemake_env/lib/python3.11/site-packages/snakemake/executors/local.py", line 234, in spawn_job
    raise SpawnedJobError()

snakemake.exceptions.SpawnedJobError

[Thu Jul 17 13:48:33 2025]
Error in rule python_write:
    message: None
    jobid: 2
    output: s2_python.txt
Shutting down, this might take some time.
Exiting because a job execution failed. Look below for error messages
[Thu Jul 17 13:48:33 2025]
Error in rule python_write:
    message: None
    jobid: 2
    output: s2_python.txt
Complete log(s): /Users/russell/Code/snakehive/russell/.snakemake/log/2025-07-17T134832.139043.snakemake.log
WorkflowError:
At least one job did not complete successfully.
